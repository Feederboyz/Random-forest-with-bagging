{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import sys          \n",
    "import random       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = pd.read_csv('./input/house-prices-advanced-regression-techniques/train.csv', index_col='Id')\n",
    "# choose last 10 data as test data                                                         \n",
    "X_test_full = X_full.iloc[-10:,:]                                        \n",
    "X_full = X_full.iloc[:-10,:]                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Selection\n",
    "Only sellect numerical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features after drop:\n",
      "OverallQual\n",
      "YearBuilt\n",
      "YearRemodAdd\n",
      "MasVnrArea\n",
      "TotalBsmtSF\n",
      "1stFlrSF\n",
      "GrLivArea\n",
      "FullBath\n",
      "TotRmsAbvGrd\n",
      "Fireplaces\n",
      "GarageYrBlt\n",
      "GarageCars\n",
      "SalePrice\n"
     ]
    }
   ],
   "source": [
    "# Select numerical features only                       \n",
    "X_full = X_full.select_dtypes(exclude='object')        \n",
    "                                                       \n",
    "# Drop features which corr value is less than 0.4      \n",
    "X_full = X_full.loc[:,X_full.corr()['SalePrice'] > 0.4]\n",
    "                                                       \n",
    "# Drop feature GarageArea because it is almost as same as GarageCars\n",
    "features_to_be_droped = ['GarageArea']                 \n",
    "X_full = X_full.drop(features_to_be_droped, axis=1)    \n",
    "                                                       \n",
    "print(\"Features after drop:\")                          \n",
    "for feature_name in X_full:                            \n",
    "    print(feature_name)                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Missing\n",
    "Dealing with data missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GarageYrBlt    79\n",
      "MasVnrArea      8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Number of missing values in each column of training data                \n",
    "data_missing_cnt = X_full.isnull().sum()                                  \n",
    "print(data_missing_cnt[data_missing_cnt > 0].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop feature 'GarageYrBlt' because there is a lot of missing value\n",
    "X_full = X_full.drop('GarageYrBlt', axis=1)            \n",
    "                                                       \n",
    "# Remove observations which 'MasVnrArea' is null       \n",
    "X_full = X_full.dropna(axis = 0, subset=['MasVnrArea'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the number of entries with missing values in each column\n",
    "data_missing_cnt = X_full.isnull().sum()\n",
    "print(data_missing_cnt[data_missing_cnt > 0].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sellected_features = ['OverallQual', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', \n",
    "                      'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'FullBath', \n",
    "                      'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'SalePrice']\n",
    "X_test_full = X_test_full[sellected_features]\n",
    "X_test_full = X_test_full.dropna(axis = 0, subset=sellected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structure of Rondom forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:                                                                  \n",
    "    def __init__(self, left=None, right=None, feature_name=None, threshold=None, predicted_value=None, data_cnt=None):\n",
    "        # Only be used at internal node                                      \n",
    "        self.left = left                                                     \n",
    "        self.right = right                                                   \n",
    "        self.feature_name = feature_name                                     \n",
    "        self.threshold = threshold                                           \n",
    "                                                                             \n",
    "        # Only be used at leaf node                                          \n",
    "        self.predicted_value = predicted_value                               \n",
    "                                                                             \n",
    "        # For debug                                                          \n",
    "        self.data_cnt = data_cnt                                             \n",
    "                                                                             \n",
    "# class of DecisionTree                                                      \n",
    "class DecisionTree:                                                          \n",
    "    def __init__(self, max_depth, target_name, iter_feature_cnt, min_sample_cnt, loss_type):\n",
    "        self.root = None                                                     \n",
    "        self.max_depth = max_depth                                           \n",
    "        self.target_name = target_name                                       \n",
    "                                                                             \n",
    "        # How many features will be choosed in each iteration during new node creation\n",
    "        self.iter_feature_cnt = iter_feature_cnt                             \n",
    "                                                                             \n",
    "        # Used for randomly pick features                                    \n",
    "        self.dice = None                                                     \n",
    "        self.feature_list = None                                             \n",
    "                                                                             \n",
    "        # If the sample count is less than min_sample_cnt, stop creating new node.\n",
    "        self.min_sample_cnt = min_sample_cnt                                 \n",
    "        self.loss_type = loss_type                                           \n",
    "                                                                             \n",
    "    def fit(self, dataset):                                                  \n",
    "        self.tree_init(dataset)                                              \n",
    "        self.root = self.create_node(dataset=dataset, curr_depth=1)          \n",
    "                                                                             \n",
    "    def tree_init(self, dataset):                                            \n",
    "        self.feature_list = list(dataset.columns)                            \n",
    "        self.feature_list.remove(self.target_name)                           \n",
    "        self.dice = range(len(self.feature_list))                            \n",
    "                                                                             \n",
    "    def create_node(self, dataset, curr_depth):                              \n",
    "        # Use recursion to create the whole decision tree                    \n",
    "                                                                             \n",
    "        # If the following two items is True, return a node with left & right child node.\n",
    "        # 1. Current depth less than max depth                               \n",
    "        # 2. Data count larger than minimum sample count                     \n",
    "        if curr_depth <= self.max_depth and len(dataset) >= self.min_sample_cnt:\n",
    "            feature_name, threshold, left_dataset, right_dataset = self.best_split(dataset)\n",
    "                                                                             \n",
    "            # Create internal node                                           \n",
    "            return Node(left=self.create_node(left_dataset, curr_depth+1),   \n",
    "                        right=self.create_node(right_dataset, curr_depth+1), \n",
    "                        feature_name=feature_name,                           \n",
    "                        threshold=threshold,                                 \n",
    "                        data_cnt=dataset.shape[0])                           \n",
    "                                                                             \n",
    "        # Otherwise, return a leaf node.                                     \n",
    "        predicted_value = dataset[self.target_name].mean()                   \n",
    "        return Node(predicted_value=predicted_value,                         \n",
    "                    data_cnt=dataset.shape[0])                               \n",
    "                                                                             \n",
    "    def roll_dice(self):                                                     \n",
    "        # Used for randomly choose features                                  \n",
    "        # The size of dice is equal to features count                        \n",
    "        self.dice = random.sample(self.dice, len(self.dice))                 \n",
    "                                                                             \n",
    "    def best_split(self, dataset):                                           \n",
    "        min_loss = sys.float_info.max                                        \n",
    "        best_feature_name = None                                             \n",
    "        best_threshold = None                                                \n",
    "                                                                             \n",
    "        # Selcet feature                                                     \n",
    "        self.roll_dice()                                                     \n",
    "        for i in range(self.iter_feature_cnt):                               \n",
    "            curr_feature_name = self.feature_list[self.dice[i]]              \n",
    "                                                                             \n",
    "            # Select threshold                                               \n",
    "            unique_value_list = np.unique(dataset[curr_feature_name])        \n",
    "            for idx in range(len(unique_value_list) - 1):                    \n",
    "                curr_threshold = (unique_value_list[idx] + unique_value_list[idx+1]) / 2\n",
    "                                                                             \n",
    "                # Split & compute loss                                       \n",
    "                left_dataset, right_dataset = self.split(dataset, curr_feature_name, curr_threshold)\n",
    "                curr_loss = self.compute_loss(left_dataset[self.target_name], \n",
    "                                              right_dataset[self.target_name])\n",
    "                                                                             \n",
    "                if curr_loss < min_loss:                                     \n",
    "                    best_left_dataset, best_right_dataset = left_dataset, right_dataset\n",
    "                    best_feature_name = curr_feature_name                    \n",
    "                    best_threshold = curr_threshold                          \n",
    "                    min_loss = curr_loss                                     \n",
    "                                                                             \n",
    "        return best_feature_name, best_threshold, best_left_dataset, best_right_dataset\n",
    "                                                                             \n",
    "    def split(self, dataset, feature_name, threshold):                       \n",
    "        left_dataset = dataset[dataset[feature_name] <= threshold]           \n",
    "        right_dataset = dataset[dataset[feature_name] > threshold]           \n",
    "        return left_dataset, right_dataset                                   \n",
    "                                                                             \n",
    "    def compute_loss(self, left_y, right_y):                                 \n",
    "        if self.loss_type == 'MAE':                                          \n",
    "            return self.MAE(left_y) + self.MAE(right_y)                      \n",
    "        else:                                                                \n",
    "            raise ValueError(\"Parameter 'loss_type': \" + self.loss_type + \" is invalid.\")\n",
    "                                                                             \n",
    "    def MAE(self, y):                                                        \n",
    "        return sum([(ele - sum(y)) ** 2 for ele in y])                       \n",
    "                                                                             \n",
    "    def predict_all(self, X):                                                \n",
    "        data_cnt = len(X)                                                    \n",
    "        y = [self.predict_single(X.iloc[i,:]) for i in range(data_cnt)]      \n",
    "        return y                                                             \n",
    "                                                                             \n",
    "    def predict_single(self, x):                                             \n",
    "        curr_node = self.root                                                \n",
    "                                                                             \n",
    "        while curr_node.predicted_value == None:                             \n",
    "            if x[curr_node.feature_name] <= curr_node.threshold:             \n",
    "                curr_node = curr_node.left                                   \n",
    "            else:                                                            \n",
    "                curr_node = curr_node.right                                  \n",
    "        return curr_node.predicted_value                                     \n",
    "                                                                             \n",
    "    def print_prediction(self, y, pred_y):                                   \n",
    "        for i in range(len(y)):                                              \n",
    "            print('Observation: ' + str(y[i]), end='\\t')                     \n",
    "            print('Prediction: ' + str(list(pred_y)[i]))                     \n",
    "                                                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structure of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:                                                                   \n",
    "    def __init__(self, tree_cnt, max_depth, target_name, iter_feature_cnt, min_sample_cnt, loss_type):\n",
    "        self.tree_cnt = tree_cnt                                                      \n",
    "        self.max_depth = max_depth                                                    \n",
    "        self.target_name = target_name                                                \n",
    "        self.loss_type = loss_type                                                    \n",
    "                                                                                      \n",
    "        # How many features will be choosed in each iteration during new node creation\n",
    "        self.iter_feature_cnt = iter_feature_cnt                                      \n",
    "                                                                                      \n",
    "        # If the sample count is less than min_sample_cnt, stop creating new node.    \n",
    "        self.min_sample_cnt = min_sample_cnt                                          \n",
    "                                                                                      \n",
    "        self.tree_list = []                                                           \n",
    "                                                                                      \n",
    "    def fit(self, dataset):                                                           \n",
    "        for i in range(tree_cnt):                                                     \n",
    "            print('Fitting tree ' + str(i))                                           \n",
    "                                                                                      \n",
    "            # Randomly pick observations(bagging)                                     \n",
    "            data_cnt = dataset.shape[0]                                               \n",
    "            new_dataset = pd.DataFrame(columns=dataset.columns)                       \n",
    "            for j in range(data_cnt):                                                 \n",
    "                idx = random.randint(0, data_cnt-1)                                   \n",
    "                new_dataset.loc[j] = list(dataset.iloc[idx,:])                        \n",
    "                                                                                      \n",
    "            # Fitting decision tree with randomly pick observations                   \n",
    "            dt = DecisionTree(self.max_depth,                                         \n",
    "                              self.target_name,                                       \n",
    "                              self.iter_feature_cnt,                                  \n",
    "                              self.min_sample_cnt,                                    \n",
    "                              self.loss_type)                                         \n",
    "            dt.fit(new_dataset)                                                       \n",
    "            self.tree_list.append(dt)                                                 \n",
    "                                                                                      \n",
    "    def predict_all(self, X):                                                         \n",
    "        curr_dt = self.tree_list[0]                                                   \n",
    "        tree_cnt = len(self.tree_list)                                                \n",
    "        pred_y = curr_dt.predict_all(X)                                               \n",
    "                                                                                      \n",
    "        for i in range(1, tree_cnt):                                                  \n",
    "            curr_dt = self.tree_list[i]                                               \n",
    "            pred_y_tmp = curr_dt.predict_all(X)                                       \n",
    "            pred_y = [sum(ele) for ele in zip(pred_y, pred_y_tmp)]                    \n",
    "                                                                                      \n",
    "        pred_y = [ele / tree_cnt for ele in pred_y]                                   \n",
    "        return pred_y                                                                 \n",
    "                                                                                      \n",
    "    def print_prediction(self, y, pred_y):                                            \n",
    "        for i in range(len(y)):                                                       \n",
    "            print('Observation: ' + str(y.iloc[i]), end='\\t')                         \n",
    "            print('Prediction: ' + str(list(pred_y)[i]), end='\\t')                    \n",
    "            print('MAE = ' + str((y.iloc[i] - list(pred_y)[i]) ** 2) )                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting tree 0\n"
     ]
    }
   ],
   "source": [
    "tree_cnt = 1              \n",
    "max_depth = 1             \n",
    "target_name = 'SalePrice' \n",
    "iter_feature_cnt = 1      \n",
    "min_sample_cnt = 50       \n",
    "loss_type = 'MAE'         \n",
    "                          \n",
    "rf = RandomForest(tree_cnt, max_depth, target_name, iter_feature_cnt, min_sample_cnt, loss_type)\n",
    "rf.fit(X_full)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: 136000\tPrediction: 151956.89199029127\tMAE = 254622401.98982185\n",
      "Observation: 287090\tPrediction: 235094.08899676375\tMAE = 2703574761.0564647\n",
      "Observation: 145000\tPrediction: 151956.89199029127\tMAE = 48398346.16457889\n",
      "Observation: 84500\tPrediction: 151956.89199029127\tMAE = 4550432276.989823\n",
      "Observation: 185000\tPrediction: 235094.08899676375\tMAE = 2509417752.415687\n",
      "Observation: 175000\tPrediction: 151956.89199029127\tMAE = 530984826.7471024\n",
      "Observation: 210000\tPrediction: 235094.08899676375\tMAE = 629713302.5774994\n",
      "Observation: 266500\tPrediction: 235094.08899676375\tMAE = 986331245.9431958\n",
      "Observation: 142125\tPrediction: 151956.89199029127\tMAE = 96666100.10875373\n",
      "Observation: 147500\tPrediction: 235094.08899676375\tMAE = 7672724427.172968\n"
     ]
    }
   ],
   "source": [
    "pred_y = rf.predict_all(X_test_full)                 \n",
    "rf.print_prediction(X_test_full[target_name], pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting tree 0\n",
      "Fitting tree 1\n",
      "Fitting tree 2\n",
      "Fitting tree 3\n",
      "Fitting tree 4\n",
      "Fitting tree 5\n",
      "Fitting tree 6\n",
      "Fitting tree 7\n",
      "Fitting tree 8\n",
      "Fitting tree 9\n"
     ]
    }
   ],
   "source": [
    "tree_cnt = 10                                                                  \n",
    "max_depth = 1                                                                  \n",
    "target_name = 'SalePrice'                                                      \n",
    "iter_feature_cnt = 1                                                           \n",
    "min_sample_cnt = 50                                                            \n",
    "loss_type = 'MAE'                                                              \n",
    "                                                                               \n",
    "rf2 = RandomForest(tree_cnt, max_depth, target_name, iter_feature_cnt, min_sample_cnt, loss_type)\n",
    "rf2.fit(X_full)                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: 136000\tPrediction: 158893.0303532661\tMAE = 524090838.7555632\n",
      "Observation: 287090\tPrediction: 225416.27516896892\tMAE = 3803648334.53374\n",
      "Observation: 145000\tPrediction: 169604.85295299167\tMAE = 605398788.8383429\n",
      "Observation: 84500\tPrediction: 149709.11278700645\tMAE = 4252228390.4685283\n",
      "Observation: 185000\tPrediction: 199872.4635612333\tMAE = 221190172.38021252\n",
      "Observation: 175000\tPrediction: 180779.55189083423\tMAE = 33403220.058845576\n",
      "Observation: 210000\tPrediction: 185644.09274720986\tMAE = 593210218.1065155\n",
      "Observation: 266500\tPrediction: 205520.5350029837\tMAE = 3718495151.322336\n",
      "Observation: 142125\tPrediction: 143041.61698389036\tMAE = 840186.6951562583\n",
      "Observation: 147500\tPrediction: 143041.61698389036\tMAE = 19877179.1183349\n"
     ]
    }
   ],
   "source": [
    "pred_2_y = rf2.predict_all(X_test_full)                 \n",
    "rf2.print_prediction(X_test_full[target_name], pred_2_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d07ada2db3a750ea7525ef0abae1dd8d2e024d709104a053d6ba9a14985ab36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
